{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selectivesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-391a403f20cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mselectivesearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selectivesearch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal as sig\n",
    "import skimage.segmentation\n",
    "from matplotlib import pyplot as plt\n",
    "import selectivesearch \n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> Влияние глубокого обучения на выделение объектов </font>\n",
    "![Segmentation](./img/Detection01.png)\n",
    "\n",
    "О том, что такое mAP в детекции: https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Segmentation](./img/Detection02.png)\n",
    "\n",
    "<font color=blue size=5>Проблема:  объектов на картинке много. Что можно сделать?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> Region Proposals (RoI - Region of Interest) </font>\n",
    "\n",
    "- Можно найти регионы, на которых наиболее вероятно есть объекты\n",
    "- Методы, которые находять такие ригионы известны, например, Selective Search. Дает 1000 region proposals за несколько seconds на CPU\n",
    "![Segmentation](./img/Detection03.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> Image Segmentation (Felzenszwalb’s Algorithm) [Old School] </font>\n",
    "_Felzenszwalb and Huttenlocher(2004)_ представили алгоритм для сегментации изображения. Изображение в данном алгоритме представляется в виде неориентированного графа $G=(V,E)$, где $v_i \\in V$ - вершины графа(пиксели изображения), а $e = (v_i,v_j) \\in E$ - дуги. Веса $w(v_i,v_j)$ соответствующие дугам, отражают меру непохожести между пикселями, которая может быть рассчитана по следующим параметрам:\n",
    " * Цвет\n",
    " * Положение пикселей\n",
    " * Гамма\n",
    " * Яркость\n",
    "---\n",
    "Решением задачи сегментации $S$ является некоторое разбиение множества $V$ на множества связанных компонент $\\{C\\}$. Интуитивно, разбиение должно быть таким, чтобы похожие пиксели находились в одной компоненте, а не похожие - в разных.\n",
    "Варианты построения графа изображения:\n",
    " * В виде __регулярной сетки__, когда каждый пиксель соединен только с 8-ю соседями.\n",
    " * В виде __графа ближайших соседей__, когда каждый пиксель представляется в виде в виде точки в пространсте $(x,y,r,g,b)$ и с $n$ ближайшими соседями на основе Евклидова расстояния между векторами пикселей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key koncepts:\n",
    " * __Internal difference__ : $Int(C) = \\max_{e\\in MST(C, E)} w(e)$, где $MST$ - это остовное дерево минимального веса для компоненты $\\{C\\}$. \n",
    " * __Difference between two components__ : $Dif(C_1, C_2) = \\min_{v_i \\in C_1, v_j \\in C_2, (v_i, v_j) \\in E} w(v_i, v_j). Dif(C_1,C_2) = \\infty$, если между двумя компонентами нету дуги.\n",
    " * __Minimum internal difference__ : $MInt(C_1, C_2) = min(Int(C_1) + \\tau(C_1), Int(C_2) + \\tau(C_2)), где \\tau(C) = k / \\vert C \\vert $ - величина, ограничивающая оценку снизу. Чем выше эта величина, тем более крупными будут связные компоненты.\n",
    " * __Segmentation quality predicate__ : $D(C_1, C_2) =\n",
    "\\begin{cases}\n",
    "  \\text{True} & \\text{ if } Dif(C_1, C_2) > MInt(C_1, C_2) \\\\\n",
    "  \\text{False} & \\text{ otherwise}\n",
    "\\end{cases}$. В случае, когда предикат принимает значние $True$, мы можем рассматривать компоненты $\\{C1\\} и \\{C2\\}$, как независимые, иначе они должны быть слиты в одну."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм сегментации:\n",
    "Дано : изображение $G=(V,E), |V|=n, |E|=m$\n",
    "1. Отсортировать дуги в порядке возрастания значений их весов: $e_1, e_2, \\dots, e_m$\n",
    "2. Помещаем каждый пиксель в свою компоненту. Т.о. на старте алгоритма у нас $n$ независимых компонент.\n",
    "3. Повторить для $k=1, \\dots, m$:\n",
    "    * Обозначим решение задачи сегментации для шага $k$ через $S_k$\n",
    "    * Рассмотрим дугу $e_k = (v_i, v_j)$\n",
    "    * Если $v_i$ и $v_j$ принадлежат одной компоненте, то $S_k = S_{k-1}$\n",
    "    * Если $v_i$ и $v_j$ принадлежат разным компонентам $C_i^{k-1}$ и $C_j^{k-1}$, то в случае, если $w(v_i, v_j) \\leq MInt(C_i^{k-1}, C_j^{k-1})$ мы сливаем их в одну компоненту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './img/nba_g_kobe_manu_580.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f13376da9753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./img/nba_g_kobe_manu_580.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msegment_mask1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfelzenszwalb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msegment_mask2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfelzenszwalb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(name, flatten, mode)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2610\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './img/nba_g_kobe_manu_580.jpg'"
     ]
    }
   ],
   "source": [
    "img2 = scipy.misc.imread(\"./img/nba_g_kobe_manu_580.jpg\")\n",
    "segment_mask1 = skimage.segmentation.felzenszwalb(img2, scale=100)\n",
    "segment_mask2 = skimage.segmentation.felzenszwalb(img2, scale=1000)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax0 = fig.add_subplot(131)\n",
    "ax1 = fig.add_subplot(132)\n",
    "ax2 = fig.add_subplot(133)\n",
    "ax0.imshow(img2); ax0.set_xlabel(\"original\")\n",
    "ax1.imshow(segment_mask1); ax1.set_xlabel(\"k=100\")\n",
    "ax2.imshow(segment_mask2); ax2.set_xlabel(\"k=1000\")\n",
    "fig.suptitle(\"Felsenszwalb's efficient graph based image segmentation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> Selective Search [Old School] </font>\n",
    "Классический алгоритм для поиска регионов изображения, которые потенциально содержат объекты. Для работы алгоритм использует сегментированное изображение.\n",
    "\n",
    "---\n",
    "\n",
    "### Алгоритм selective search:\n",
    "\n",
    "![Segmentation](./img/sel_search.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './img/nba_g_kobe_manu_580.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cd151093fbe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./img/nba_g_kobe_manu_580.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mpatch_cand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_selective_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(name, flatten, mode)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2610\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './img/nba_g_kobe_manu_580.jpg'"
     ]
    }
   ],
   "source": [
    "def do_selective_search(img):\n",
    "    img_lbl, regions = selectivesearch.selective_search(img, scale=1000, sigma=0.9, min_size=10)\n",
    "    candidates = set()\n",
    "    for r in regions:\n",
    "        # excluding same rectangle (with different segments)\n",
    "        if r['rect'] in candidates:\n",
    "            continue\n",
    "        # excluding regions smaller than 2000 pixels\n",
    "        if r['size'] < 2000:\n",
    "            continue\n",
    "        # distorted rects\n",
    "        x, y, w, h = r['rect']\n",
    "        if w / h > 1.2 or h / w > 1.2:\n",
    "            continue\n",
    "        candidates.add(r['rect'])\n",
    "\n",
    "    # draw rectangles on the original image\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 20))\n",
    "    ax.imshow(img)\n",
    "    for x, y, w, h in candidates:\n",
    "        rect = mpatches.Rectangle(\n",
    "            (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "    return candidates\n",
    "\n",
    "img = scipy.misc.imread(\"./img/nba_g_kobe_manu_580.jpg\")\n",
    "patch_cand = do_selective_search(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> R-CNN </font>\n",
    "![Segmentation](./img/Detection04.png)\n",
    " 1. Берем предобученную на ImageNet сверточную нейронную сеть, например VGG или ResNet.\n",
    " 2. При помощи SelectiveSearch отбираем регионы, на которых с наибольшей вероятностью находятся, интересующие нас, объекты ~(2k за 1-2 сек на CPU)\n",
    " 3. Каждый регион трансформируем под размер входа сети и прогоняем нее.\n",
    " 4. Производим fine-tuning CNN, через обучение классификатора на RoI (K + 1 класс, отвечающий за background).\n",
    " 5. Фиксируем CNN и обучаем для каждого из K+1 классов binary-SVM классфикатор. В качестве позитивных примеров класса берем те RoI, для которых IoU >= 0.3\n",
    " <img src=\"./img/iou_equation.png\" width=\"30%\">\n",
    " 6. Обучаем отдельно Bbox-regression svm по типу п.5\n",
    " ---\n",
    " * Медленное обучение\n",
    " * Много места на диске\n",
    " * Медленное предсказание\n",
    " \n",
    " --- \n",
    " <font size=5 color=blue>Решение: делать все за один проход</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> Fast R-CNN </font>\n",
    "![Segmentation](./img/Detection05.png)\n",
    "1. Берем предобученную на ImageNet сеть.\n",
    "2. Изменяем сетку из п1.:\n",
    "     * Выкидываем последний MaxPooling слой и заменяем его на __RoI-Pooling__ слой.\n",
    "     * Выкидываем FC+SoftMax и заменяем на 2 слоя: __FC+SoftMax__(для классификации на K+1 классов), __FC__ - для предсказания bounding-box'ов.\n",
    "3. При помощи SelectiveSearch отбираем регионы, на которых с наибольшей вероятностью находятся, интересующие нас, объекты ~(2k за 1-2 сек на CPU)\n",
    "4. Подаем картинку и RoI  в одном батче в сеть\n",
    "5. На последнем конволюционном слое находим проекцию RoI на фичемапу\n",
    "6. Проекцию RoI пропускаем через RoI Pooling слой и получаем фичи, которые уже используются для классификации и построения bounding-box'а.\n",
    "\n",
    "---\n",
    "\n",
    "* Время работы определяется работой алгоритма для нахождения RoI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoI Pooling\n",
    "<img src=\"./img/roi_pooling.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task Loss\n",
    "\n",
    "Модель оптимизируется при помощи multi-task loss.\n",
    "\n",
    "---\n",
    "\n",
    "* $u$ - истинный класс для объекта на RoI, $u \\in 0, 1, \\dots, K, u = 0$ для background'а\n",
    "* $p$ - вероятность принадлежности RoI к $k+1$ классу $p = (p_0, \\dots, p_K)$, рассчитывается при помощи softmax\n",
    "* $v$ - истинная bounding-box $v = (v_x, v_y, v_w, v_h)$\n",
    "* $t^u$ - bounding-box, предсказанный моделью $t^u = (t^u_x, t^u_y, t^u_w, t^u_h)$\n",
    "\n",
    "---\n",
    "\n",
    "Loss-функция состоит из ошибки классификации и ошибки определения b-box'а : $\\mathcal{L} = \\mathcal{L}_\\text{cls} + \\mathcal{L}_\\text{box}$. При обучении, для класса $K=0$, игнорируем $\\mathcal{L}_\\text{box}$ посредством индикаторной функции $\\mathbb{1} [u \\geq 1]$.\n",
    "<center>\n",
    "$\n",
    "\\mathbb{1} [u \\geq 1] = \n",
    "\\begin{cases}\n",
    "    1  & \\text{if } u \\geq 1\\\\\n",
    "    0  & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "</center>\n",
    "Таким образом общий вид лосса:\n",
    "<center>\n",
    "$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(p, u, t^u, v) &= \\mathcal{L}_\\text{cls} (p, u) + \\mathbb{1} [u \\geq 1] \\mathcal{L}_\\text{box}(t^u, v) \\\\\n",
    "\\mathcal{L}_\\text{cls}(p, u) &= -\\log p_u \\\\\n",
    "\\mathcal{L}_\\text{box}(t^u, v) &= \\sum_{i \\in \\{x, y, w, h\\}} L_1^\\text{smooth} (t^u_i - v_i)\n",
    "\\end{align*}\n",
    "$\n",
    "</center>\n",
    "<center>\n",
    "Где, \n",
    "$ \n",
    "L_1^\\text{smooth}(x) = \\begin{cases}\n",
    "    0.5 x^2             & \\text{if } \\vert x \\vert < 1\\\\\n",
    "    \\vert x \\vert - 0.5 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n",
    "</center>\n",
    "<img src=\"./img/robust_l1_loss.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Время предсказания с учетом и без учета нахождения Region Proposals\n",
    "![Segmentation](./img/Detection06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> Faster R-CNN </font>\n",
    "![Segmentation](./img/Detection07.png)\n",
    "\n",
    "### Архитектура\n",
    "\n",
    "Состоит из 2 CNN сеток : \n",
    "* RPN(Region Proposal Network)\n",
    "* Fast R-CNN\n",
    "* Но, можно и обойтись до __одной__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN Anchors\n",
    "\n",
    "<img src=\"./img/Anchors.png\" width=\"50%\">\n",
    "\n",
    "1. Окно размером 3x3, которым мы скользим по feature-map картинки.\n",
    "\n",
    "2. Каждому положению окна на fm соответсвуют anchor'ы, которые различаются:\n",
    "    * по разрешению : 128x128, 256x256, 512x512\n",
    "    * по соотношению сторон : 1:1, 1:2, 2:1\n",
    "\n",
    "Итого 9 регионов anchor'ов на одно положение окна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение RPN\n",
    "\n",
    "Обходим окошком(3x3) feature-map и генерируем RoI, на которых будем обучаться. В обучение берем только те RoI, для которых IoU > 0.7(positive class) и IoU < 0.3 (negative class)\n",
    "\n",
    "### RPN Loss\n",
    "\n",
    "Для обучения RPN так же используем multi-task loss:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\mathcal{L}_\\text{cls} + \\mathcal{L}_\\text{box} \\\\\n",
    "\\mathcal{L}(\\{p_i\\}, \\{t_i\\}) &= \\frac{1}{N_\\text{cls}} \\sum_i \\mathcal{L}_\\text{cls} (p_i, p^*_i) + \\frac{\\lambda}{N_\\text{box}} \\sum_i p^*_i \\cdot L_1^\\text{smooth}(t_i - t^*_i) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "<center>\n",
    "$\\mathcal{L}_\\text{cls} (p_i, p^*_i) = - p^*_i \\log p_i - (1 - p^*_i) \\log (1 - p_i)$\n",
    "</center>\n",
    "\n",
    "Обозначения:\n",
    "* $p_i$ - предсказанная вероятность, что anchor содержит объект\n",
    "* $p^*_i$ - истинная вероятность, что anchor содержит объект\n",
    "* $t_i$ - предсказанный вектор координат bounding box'a anchor'a\n",
    "* $t^*_i$ - истинный вектор координат bounding box'a anchor'a\n",
    "* $N_\\text{cls}$ - нормировочный коэффициент(по кол-ву anchor'оv/размеру мини-батча) = 256(128 - positive, 128 - negative)\n",
    "* $N_\\text{box}$ - нормировочный коэффициент(по кол-ву расположений anchor'оv) = ~2400\n",
    "* $\\lambda$ - балансирующи коэффициент, для того, чтобы оба лосса имели одинаковое влияние на обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow тренировки всей сети\n",
    "1. Берем CNN предобученную на ImageNet (СNN1)\n",
    "2. Обучаем только слои RPN на фичах, сгенеренных сетью СNN1\n",
    "3. Обучаем Fast R-CNN детектор на тех RoI, которые нам предсказала RPN (СNN2)\n",
    "4. Дообучаем RPN-слои на фичах от сети (CNN2), при этом веса сети CNN2 зафиксированы\n",
    "5. Дообучаем детектор и классификатор Fast R-CNN на регионах от RPN после п.4\n",
    "6. Повторяем п.4 и п.5 до сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentation](./img/Detection12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font size=10 color=blue> Instance Segmentation </font>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> Mask R-CNN </font>\n",
    "![Segmentation](./img/Detection08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Является той же самой Faster R-CNN, но в части детектора и классфикатора добавляется еще один слой, отвечающий за предсказание попиксельной маски объекта на изображении. Поскольку предсказание маски является операцией, требующей более высокой точности, то нам необходимо заменить RoIPooling слой на RoIAlign cлой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoiAlign слой\n",
    "Основная идея RoIAlign слоя в том, что при pooling'е границы сетки не дискретезируются.\n",
    "Вместо этого, каждая ячейка \"пулинга\" получается одинакового размера и для вычисления значений в ячейке используется __билинейная интерполяция__.\n",
    "\n",
    "<img src=\"./img/roi_align.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss-функция\n",
    "\n",
    "В данной модели у нас к имеющимся loss'ам Faster R-CNN добавляется еще одна компонента: $\\mathcal{L} = \\mathcal{L}_\\text{cls} + \\mathcal{L}_\\text{box} + \\mathcal{L}_\\text{mask}$. Для каждого RoI модель предсказывает маску размером $m\\ x\\ m$ для каждого из классов $K$. Таким образом мы работаем с выходом размерности $K \\cdot m^2$. $\\mathcal{L}_\\text{mask}$ рассчитывается только для класса $k$, если последний является истиным для данного региона. \n",
    "\n",
    "\n",
    "<center>\n",
    "$\\mathcal{L}_\\text{mask} = - \\frac{1}{m^2} \\sum_{1 \\leq i, j \\leq m} \\big[ y_{ij} \\log \\hat{y}^k_{ij} + (1-y_{ij}) \\log (1- \\hat{y}^k_{ij}) \\big]$,\n",
    "</center>\n",
    "\n",
    "где $y_{ij}$ это истинный класс ячейки $(i,j)$, а $\\hat{y}_{ij}^k$ - вероятность класса $k$ предсказанная моделью для той же самой ячейки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В действии\n",
    "![Segmentation](./img/Detection09.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
